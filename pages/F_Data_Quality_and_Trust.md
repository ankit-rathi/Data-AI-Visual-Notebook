# **F - Data Quality and Trust**

<img width="800" height="533" alt="image" src="https://github.com/user-attachments/assets/2d1221a0-5d93-4572-9c25-39047e0a3238" />

> From first principles, these concepts exist because data is valuable only if it can be trusted to represent reality at the right time. **Data quality** is the outcome, emerging from foundational properties such as **completeness**, which ensures no expected information is missing, **accuracy**, which ensures the data correctly reflects what actually happened, and **freshness**, which recognizes that even correct data loses value when it arrives too late. Because these properties cannot be assumed in real systems, **validation** is required to continuously check rules, ranges, structure, and timeliness. When data deviates from these expectations, an **anomaly** appears, signaling a breakdown between reality and representation. To detect such deviations reliably, systems rely on **monitoring**, which observes data behavior over time rather than at a single moment. When monitoring reveals a significant loss of trust—due to missing, incorrect, or stale data—it escalates into a **data incident**, triggering investigation and remediation to restore confidence in the data.

> Data Quality → Completeness, Accuracy, Freshness → Validation → Anomaly, Monitoring → Data Incident
