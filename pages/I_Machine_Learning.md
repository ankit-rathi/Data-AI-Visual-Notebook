# **I. Machine Learning**

<img width="1536" height="1024" alt="image" src="https://github.com/user-attachments/assets/b6f4a93d-4ae8-47c3-886f-db602ebb98e9" />

> From first principles, **features** are the measurable parts of reality that we choose to observe, while **labels** are the outcomes we want the system to predict. When features and labels are combined, they form **training data**, which contains past examples of how the world behaved. A **model** is a structured guess that tries to link features to labels, and **learning** is the process of adjusting this model so it captures patterns in the training data. If a model fits the training data too closely, it may also learn random noise, leading to **overfitting**, where it performs well on familiar data but fails on new situations. What we truly care about is **generalization**—the ability to make accurate predictions on unseen data from the same real-world process. To check this, we use **evaluation**, which tests the model on data it has not learned from. Finally, **inference** is when the trained and evaluated model is used in the real world to make predictions on new inputs.

> Feature → Label → Training Data → Model → Learning → Overfitting → Generalization → Evaluation, Inference
